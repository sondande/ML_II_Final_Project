{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f765ff",
   "metadata": {},
   "source": [
    "# Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet pandas numpy matplotlib seaborn torch torchvision facenet-pytorch insightface pytorch-metric-learning xgboost scikit-learn opencv-python onnxruntime mozuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d703f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Filtering 244 missing images: ['img_4.bmp', 'img_5.bmp', 'img_40.bmp', 'img_86.bmp', 'img_93.bmp', 'img_112.bmp', 'img_113.bmp', 'img_238.bmp', 'img_239.bmp', 'img_300.bmp', 'img_301.bmp', 'img_309.bmp', 'img_436.bmp', 'img_437.bmp', 'img_530.bmp', 'img_531.bmp', 'img_579.bmp', 'img_617.bmp', 'img_670.bmp', 'img_671.bmp', 'img_734.bmp', 'img_735.bmp', 'img_742.bmp', 'img_820.bmp', 'img_824.bmp', 'img_860.bmp', 'img_861.bmp', 'img_1036.bmp', 'img_1037.bmp', 'img_1070.bmp', 'img_1099.bmp', 'img_1121.bmp', 'img_1127.bmp', 'img_1164.bmp', 'img_1172.bmp', 'img_1173.bmp', 'img_1300.bmp', 'img_1301.bmp', 'img_1324.bmp', 'img_1325.bmp', 'img_1326.bmp', 'img_1327.bmp', 'img_1472.bmp', 'img_1473.bmp', 'img_1524.bmp', 'img_1525.bmp', 'img_1612.bmp', 'img_1613.bmp', 'img_1618.bmp', 'img_1619.bmp', 'img_1704.bmp', 'img_1718.bmp', 'img_1719.bmp', 'img_1720.bmp', 'img_1721.bmp', 'img_1822.bmp', 'img_1823.bmp', 'img_1830.bmp', 'img_1846.bmp', 'img_1847.bmp', 'img_1848.bmp', 'img_1849.bmp', 'img_1862.bmp', 'img_1863.bmp', 'img_1886.bmp', 'img_1887.bmp', 'img_1954.bmp', 'img_1955.bmp', 'img_1972.bmp', 'img_1973.bmp', 'img_2072.bmp', 'img_2073.bmp', 'img_2080.bmp', 'img_2081.bmp', 'img_2100.bmp', 'img_2101.bmp', 'img_2130.bmp', 'img_2214.bmp', 'img_2215.bmp', 'img_2238.bmp', 'img_2239.bmp', 'img_2242.bmp', 'img_2243.bmp', 'img_2244.bmp', 'img_2245.bmp', 'img_2250.bmp', 'img_2251.bmp', 'img_2284.bmp', 'img_2292.bmp', 'img_2293.bmp', 'img_2294.bmp', 'img_2295.bmp', 'img_2322.bmp', 'img_2323.bmp', 'img_2327.bmp', 'img_2468.bmp', 'img_2469.bmp', 'img_2516.bmp', 'img_2531.bmp', 'img_2532.bmp', 'img_2566.bmp', 'img_2567.bmp', 'img_2586.bmp', 'img_2587.bmp', 'img_2652.bmp', 'img_2653.bmp', 'img_2666.bmp', 'img_2667.bmp', 'img_2712.bmp', 'img_2714.bmp', 'img_2715.bmp', 'img_2722.bmp', 'img_2730.bmp', 'img_2731.bmp', 'img_2738.bmp', 'img_2739.bmp', 'img_2750.bmp', 'img_2751.bmp', 'img_2785.bmp', 'img_2842.bmp', 'img_2843.bmp', 'img_2912.bmp', 'img_2913.bmp', 'img_2954.bmp', 'img_2955.bmp', 'img_2982.bmp', 'img_2983.bmp', 'img_2986.bmp', 'img_2987.bmp', 'img_3030.bmp', 'img_3031.bmp', 'img_3039.bmp', 'img_3070.bmp', 'img_3071.bmp', 'img_3084.bmp', 'img_3085.bmp', 'img_3103.bmp', 'img_3140.bmp', 'img_3141.bmp', 'img_3146.bmp', 'img_3152.bmp', 'img_3153.bmp', 'img_3188.bmp', 'img_3189.bmp', 'img_3268.bmp', 'img_3269.bmp', 'img_3284.bmp', 'img_3285.bmp', 'img_3298.bmp', 'img_3299.bmp', 'img_3320.bmp', 'img_3321.bmp', 'img_3336.bmp', 'img_3337.bmp', 'img_3340.bmp', 'img_3341.bmp', 'img_3366.bmp', 'img_3367.bmp', 'img_3368.bmp', 'img_3376.bmp', 'img_3377.bmp', 'img_3387.bmp', 'img_3394.bmp', 'img_3404.bmp', 'img_3405.bmp', 'img_3408.bmp', 'img_3409.bmp', 'img_3424.bmp', 'img_3425.bmp', 'img_3430.bmp', 'img_3431.bmp', 'img_3498.bmp', 'img_3499.bmp', 'img_3503.bmp', 'img_3504.bmp', 'img_3505.bmp', 'img_3530.bmp', 'img_3531.bmp', 'img_3570.bmp', 'img_3571.bmp', 'img_3590.bmp', 'img_3591.bmp', 'img_3630.bmp', 'img_3631.bmp', 'img_3656.bmp', 'img_3657.bmp', 'img_3660.bmp', 'img_3680.bmp', 'img_3681.bmp', 'img_3694.bmp', 'img_3695.bmp', 'img_3726.bmp', 'img_3727.bmp', 'img_3731.bmp', 'img_3764.bmp', 'img_3765.bmp', 'img_3790.bmp', 'img_3792.bmp', 'img_3793.bmp', 'img_3794.bmp', 'img_3795.bmp', 'img_3802.bmp', 'img_3803.bmp', 'img_3812.bmp', 'img_3813.bmp', 'img_3816.bmp', 'img_3826.bmp', 'img_3840.bmp', 'img_3841.bmp', 'img_3851.bmp', 'img_3854.bmp', 'img_3855.bmp', 'img_3878.bmp', 'img_3879.bmp', 'img_3880.bmp', 'img_3881.bmp', 'img_3900.bmp', 'img_3906.bmp', 'img_3907.bmp', 'img_3921.bmp', 'img_3922.bmp', 'img_3923.bmp', 'img_3931.bmp', 'img_3958.bmp', 'img_3966.bmp', 'img_3967.bmp', 'img_3970.bmp', 'img_3971.bmp', 'img_3973.bmp', 'img_3990.bmp', 'img_3991.bmp', 'img_3994.bmp', 'img_3995.bmp', 'img_4018.bmp', 'img_4019.bmp', 'img_4104.bmp', 'img_4105.bmp', 'img_4146.bmp', 'img_4147.bmp', 'img_4168.bmp', 'img_4174.bmp', 'img_4175.bmp', 'img_4182.bmp', 'img_4183.bmp']\n",
      "Dataset contains 3962 valid entries.\n",
      "Fine-tuning embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "          exitcode = _main(fd, parent_sentinel) \n",
      "                        ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^    ^^exitcode = _main(fd, parent_sentinel)^^\n",
      "^^^^ ^^^\n",
      "  ^  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      " ^^^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^ ^ \n",
      " ^ ^  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "^^^^^ ^ ^ ^ ^ ^ ^     self = reduction.pickle.load(from_parent)\n",
      "\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "       self = reduction.pickle.load(from_parent) \n",
      "       ^^^^^^^ ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^ ^  ^ ^ ^      ^^^^^self = reduction.pickle.load(from_parent)^\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      " ^^ ^  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "^^^^ ^ ^ ^ ^ ^^^^ ^ ^ \n",
      " ^^^^^^^^^AttributeError^^: ^Can't get attribute 'BMIDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>^^\n",
      "^\n",
      "^AttributeError^: ^Can't get attribute 'BMIDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'BMIDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'BMIDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 38973, 38975) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    112\u001b[39m timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 38973) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 130\u001b[39m\n\u001b[32m    128\u001b[39m embedder.train()\n\u001b[32m    129\u001b[39m running = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbmis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UChicago/Spring 2025/Machine Learning II/Assignments/ML_II_Final_Project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1264\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1263\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1265\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1266\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 38973, 38975) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "bmi_face_predictor.py\n",
    "\n",
    "Pipeline:\n",
    " 1. Detect & align faces via MTCNN\n",
    " 2. Extract embeddings via ArcFace backbone (torch_arcface_insightface)\n",
    " 3. Add projection head and fine‑tune embeddings with Triplet Loss\n",
    " 4. Train an XGBoost regressor\n",
    " 5. Predict BMI on new images\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN\n",
    "from pytorch_metric_learning import losses, miners\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mozuma.models.arcface.pretrained import torch_arcface_insightface\n",
    "\n",
    "# 0. Device setup (CUDA > MPS > CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Face Detection & Alignment\n",
    "mtcnn = MTCNN(image_size=112, margin=0, keep_all=False, device=device)\n",
    "\n",
    "# Helper: load & align\n",
    "def load_and_align(img_path):\n",
    "    if not os.path.isfile(img_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise IOError(f\"Failed to read image: {img_path}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    aligned = mtcnn(img_rgb)\n",
    "    if aligned is None:\n",
    "        # fallback zero tensor\n",
    "        return torch.zeros(3, 112, 112, device=device)\n",
    "    return aligned.to(device)\n",
    "\n",
    "# 2. ArcFace backbone + projector\n",
    "class ArcFaceEmbedder(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        # Load pre-trained ArcFace (ResNet100) via Mozuma\n",
    "        self.backbone = torch_arcface_insightface(device=device)\n",
    "        # Freeze backbone parameters\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        # Projection head to 128-d\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,3,112,112)\n",
    "        with torch.no_grad():\n",
    "            emb = self.backbone(x)  # (B,512)\n",
    "        out = self.projector(emb)  # (B,128)\n",
    "        return nn.functional.normalize(out, p=2, dim=1)\n",
    "\n",
    "# 3. Dataset + filtering missing\n",
    "class BMIDataset(Dataset):\n",
    "    def __init__(self, df, images_dir):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        path = os.path.join(self.images_dir, row['name'])\n",
    "        aligned = load_and_align(path)\n",
    "        bmi = torch.tensor(row['bmi'], dtype=torch.float32, device=device)\n",
    "        return aligned, bmi\n",
    "\n",
    "# Filter entries with missing files\n",
    "def filter_existing(df, images_dir):\n",
    "    exists = df['name'].apply(lambda f: os.path.isfile(os.path.join(images_dir, f)))\n",
    "    missing = df.loc[~exists, 'name'].tolist()\n",
    "    if missing:\n",
    "        print(f\"Filtering {len(missing)} missing images: {missing}\")\n",
    "    return df.loc[exists].reset_index(drop=True)\n",
    "\n",
    "# Load and preprocess annotations\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df['bmi'] = df['bmi'].astype(float)\n",
    "df['is_training'] = df['is_training'].astype(int)\n",
    "df['name'] = df['name'].astype(str)\n",
    "images_dir = os.path.join('data', 'Images')\n",
    "df = filter_existing(df, images_dir)\n",
    "print(f\"Dataset contains {len(df)} valid entries.\")\n",
    "\n",
    "# Split\n",
    "train_df = df[df['is_training'] == 1]\n",
    "val_df   = df[df['is_training'] == 0]\n",
    "\n",
    "# DataLoaders\n",
    "train_ds = BMIDataset(train_df, images_dir)\n",
    "val_ds   = BMIDataset(val_df, images_dir)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 4. Model, loss, optimizer\n",
    "embedder = ArcFaceEmbedder(device).to(device)\n",
    "miner     = miners.TripletMarginMiner(margin=0.2, type_of_triplets='semi-hard')\n",
    "criterion = losses.TripletMarginLoss(margin=0.2)\n",
    "optimizer = torch.optim.AdamW(embedder.projector.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Fine‑tune projection head\n",
    "print(\"Fine-tuning embeddings...\")\n",
    "for epoch in range(10):\n",
    "    embedder.train()\n",
    "    running = 0.0\n",
    "    for imgs, bmis in train_loader:\n",
    "        feats = embedder(imgs)\n",
    "        labels = torch.round(bmis).long()\n",
    "        triplets = miner(feats, labels)\n",
    "        loss = criterion(feats, labels, triplets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running/len(train_loader):.4f}\")\n",
    "\n",
    "# 5. Extract embeddings\n",
    "def get_embeddings(df):\n",
    "    embedder.eval()\n",
    "    all_embs = []\n",
    "    for _, row in df.iterrows():\n",
    "        img = load_and_align(os.path.join(images_dir, row['name']))\n",
    "        with torch.no_grad():\n",
    "            emb = embedder(img.unsqueeze(0)).cpu().numpy().ravel()\n",
    "        all_embs.append(emb)\n",
    "    return np.vstack(all_embs)\n",
    "\n",
    "print(\"Extracting embeddings...\")\n",
    "X_train = get_embeddings(train_df)\n",
    "X_val   = get_embeddings(val_df)\n",
    "y_train = train_df['bmi'].values\n",
    "y_val   = val_df['bmi'].values\n",
    "\n",
    "# 6. Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(max_depth=6, learning_rate=0.05, n_estimators=200, objective='reg:squarederror')\n",
    "print(\"Training regressor...\")\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# 7. Evaluate\n",
    "preds = xgb_model.predict(X_val)\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, preds))\n",
    "\n",
    "# 8. Save\n",
    "torch.save(embedder.state_dict(), 'arcface_bmi_embedder.pt')\n",
    "xgb_model.save_model('bmi_xgb.json')\n",
    "\n",
    "# 9. Inference\n",
    "def predict_bmi(path):\n",
    "    img = load_and_align(path)\n",
    "    with torch.no_grad():\n",
    "        emb = embedder(img.unsqueeze(0)).cpu().numpy()\n",
    "    return xgb_model.predict(emb)[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample = train_df.iloc[0]['name']\n",
    "    print(\"Example BMI:\", predict_bmi(os.path.join(images_dir, sample)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with missing image files\n",
    "images_dir = os.path.join('data', 'Images')\n",
    "df = filter_existing_images(df, images_dir)\n",
    "print(f\"Loaded {len(df)} entries with images from {images_dir}\")\n",
    "\n",
    "# Split train/validation based on 'is_training'\n",
    "train_df = df[df['is_training'] == 1]\n",
    "val_df   = df[df['is_training'] == 0]\n",
    "\n",
    "# Create datasets\n",
    "datasets = {\n",
    "    'train': BMIDataset(train_df, images_dir),\n",
    "    'val':   BMIDataset(val_df, images_dir)\n",
    "}\n",
    "\n",
    "# 4. Fine‑tune embeddings with Triplet Loss\n",
    "miner     = miners.TripletMarginMiner(margin=0.2, type_of_triplets='semi-hard')\n",
    "criterion = losses.TripletMarginLoss(margin=0.2)\n",
    "embedder  = ArcFaceEmbedder().to(device)\n",
    "optimizer = torch.optim.AdamW(embedder.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "print(\"Training with Triplet Loss...\")\n",
    "train_loader = DataLoader(datasets['train'], batch_size=32, shuffle=True)\n",
    "for epoch in range(10):\n",
    "    embedder.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, bmis in train_loader:\n",
    "        feats = embedder(imgs)\n",
    "        labels = torch.round(bmis).long()\n",
    "        hard_pairs = miner(feats, labels)\n",
    "        loss = criterion(feats, labels, hard_pairs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} – Triplet Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 5. Extract embeddings for regression\n",
    "def extract_embeddings(df, images_dir):\n",
    "    embedder.eval()\n",
    "    embeddings = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(images_dir, row['name'])\n",
    "        aligned = load_and_align(img_path).to(device)\n",
    "        with torch.no_grad():\n",
    "            emb = embedder(aligned.unsqueeze(0)).cpu().numpy().ravel()\n",
    "        embeddings.append(emb)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Extract embeddings for training and validation sets\n",
    "print(\"Extracting embeddings for training and validation sets...\")\n",
    "X_train = extract_embeddings(train_df, images_dir)\n",
    "X_val   = extract_embeddings(val_df, images_dir)\n",
    "y_train = train_df['bmi'].values\n",
    "y_val   = val_df['bmi'].values\n",
    "\n",
    "# 6. Train XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    objective='reg:squarederror',\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost Regressor...\")\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 7. Evaluate\n",
    "print(\"Evaluating on validation set...\")\n",
    "preds = xgb_model.predict(X_val)\n",
    "print(\"Validation MAE:\", mean_absolute_error(y_val, preds))\n",
    "\n",
    "# 8. Save models\n",
    "torch.save(embedder.state_dict(), 'arcface_bmi_embedder.pth')\n",
    "xgb_model.save_model('bmi_xgb.json')\n",
    "\n",
    "# 9. Inference helper\n",
    "def predict_bmi(image_path):\n",
    "    aligned = load_and_align(image_path).to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = embedder(aligned.unsqueeze(0)).cpu().numpy()\n",
    "    return xgb_model.predict(emb)[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_name = train_df.iloc[0]['name']\n",
    "    sample_path = os.path.join(images_dir, sample_name)\n",
    "    print(\"Example prediction:\", predict_bmi(sample_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
